{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import cv2\n",
    "import retro\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "class StreetFighterEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(StreetFighterEnv, self).__init__()\n",
    "        self.env = retro.make(game='StreetFighterIISpecialChampionEdition-Genesis')\n",
    "        self.action_space = self.env.action_space\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(84, 84, 4), dtype=np.uint8)\n",
    "        self.current_state = None\n",
    "\n",
    "    def preprocess(self, frame):\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        frame = cv2.resize(frame, (84, 84), interpolation=cv2.INTER_AREA)\n",
    "        return frame[:, :, None]\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_state = self.preprocess(self.env.reset())\n",
    "        return np.concatenate([self.current_state] * 4, axis=-1)\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0\n",
    "        obs, reward, done, _ = self.env.step(action)\n",
    "        total_reward += reward\n",
    "        self.current_state = self.preprocess(obs)\n",
    "        next_state = np.concatenate([self.current_state] * 4, axis=-1)\n",
    "        return next_state, total_reward, done, {}\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        return self.env.render(mode)\n",
    "\n",
    "    def close(self):\n",
    "        self.env.close()\n",
    "\n",
    "class CustomCNN(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.spaces.Box, features_dim: int = 512):\n",
    "        super(CustomCNN, self).__init__(observation_space, features_dim)\n",
    "        n_input_channels = observation_space.shape[0]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_input_channels, 32, kernel_size=8, stride=4, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with torch.no_grad():\n",
    "            n_flatten = self.cnn(torch.as_tensor(observation_space.sample()[None]).float()).shape[1]\n",
    "\n",
    "        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(self.cnn(observations))\n",
    "\n",
    "def train_ppo():\n",
    "    env = DummyVecEnv([lambda: StreetFighterEnv()])\n",
    "\n",
    "    policy_kwargs = dict(\n",
    "        features_extractor_class=CustomCNN,\n",
    "        features_extractor_kwargs=dict(features_dim=512),\n",
    "    )\n",
    "\n",
    "    model = PPO('CnnPolicy', env, policy_kwargs=policy_kwargs, verbose=1)\n",
    "\n",
    "    checkpoint_callback = CheckpointCallback(save_freq=10000, save_path='./models/', name_prefix='ppo_model')\n",
    "    eval_callback = EvalCallback(env, best_model_save_path='./logs/', log_path='./logs/', eval_freq=500, deterministic=True, render=False)\n",
    "\n",
    "    model.learn(total_timesteps=int(1e6), callback=[checkpoint_callback, eval_callback])\n",
    "\n",
    "def test_ppo():\n",
    "    env = StreetFighterEnv()\n",
    "    model = PPO.load('models/ppo_model')\n",
    "\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        env.render()\n",
    "\n",
    "    env.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_ppo()\n",
    "    test_ppo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StreetFighterEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 100, 128)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import retro\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv,VecFrameStack\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback\n",
    "\n",
    "class StreetFighterEnv(gym.Env):\n",
    "    def __init__(self, render_mode=None):\n",
    "        super(StreetFighterEnv, self).__init__()\n",
    "        self.env = retro.make(game='StreetFighterIISpecialChampionEdition-Genesis',use_restricted_actions=retro.Actions.FILTERED)\n",
    "        self.action_space = self.env.action_space\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(1,100,128), dtype=np.uint8)\n",
    "        self.current_state = None\n",
    "        self.render_mode = render_mode\n",
    "        self.score = 0;\n",
    "        self.health = 176;\n",
    "\n",
    "    def preprocess(self, frame):\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        frame = cv2.resize(frame, (128,100), interpolation=cv2.INTER_AREA)\n",
    "        frame = np.reshape(frame,(1,100,128))\n",
    "        return frame\n",
    "\n",
    "    def reset(self):\n",
    "        obs = self.env.reset()\n",
    "        self.health = 176\n",
    "        self.score = 0\n",
    "        self.current_state = self.preprocess(obs)\n",
    "        # return np.concatenate([self.current_state] * 3, axis=0)\n",
    "        return self.current_state\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        score = info['score']-self.score\n",
    "        health = self.health-info['health']\n",
    "        self.score = info['score']\n",
    "        self.health = info['health']\n",
    "        total_reward += score\n",
    "        total_reward -= health*10\n",
    "        \n",
    "        self.current_state = self.preprocess(obs)\n",
    "        # next_state = np.concatenate([self.current_state] * 3, axis=0)\n",
    "        return self.current_state, total_reward, done, info\n",
    "\n",
    "    def render(self,*args,**kwargs):\n",
    "        if self.render_mode == 'human':\n",
    "            self.env.render(mode='human')\n",
    "\n",
    "    def close(self):\n",
    "        self.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DummyVecEnv([lambda: StreetFighterEnv(render_mode='human')])\n",
    "env = VecFrameStack(env,n_stack = 3,channels_order = 'last')\n",
    "model = PPO('CnnPolicy', env, verbose=1)\n",
    "\n",
    "checkpoint_callback = CheckpointCallback(save_freq=10000, save_path='./models/', name_prefix='ppo_model')\n",
    "eval_callback = EvalCallback(env, best_model_save_path='./logs/', log_path='./logs/', eval_freq=500, deterministic=True, render=False)\n",
    "\n",
    "model.learn(total_timesteps=int(1e6), callback=[checkpoint_callback, eval_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mvswa\\reinforcement\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env = StreetFighterEnv(render_mode = 'human')\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecFrameStack(env, n_stack = 3,channels_order = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 100, 128)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StreetFighterEnv(render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mvswa\\reinforcement\\.venv\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:167: UserWarning: Could not deserialize object learning_rate. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: Can't get attribute '_make_function' on <module 'cloudpickle.cloudpickle' from 'c:\\\\Users\\\\mvswa\\\\reinforcement\\\\.venv\\\\lib\\\\site-packages\\\\cloudpickle\\\\cloudpickle.py'>\n",
      "  warnings.warn(\n",
      "c:\\Users\\mvswa\\reinforcement\\.venv\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:167: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: Can't get attribute '_make_function' on <module 'cloudpickle.cloudpickle' from 'c:\\\\Users\\\\mvswa\\\\reinforcement\\\\.venv\\\\lib\\\\site-packages\\\\cloudpickle\\\\cloudpickle.py'>\n",
      "  warnings.warn(\n",
      "c:\\Users\\mvswa\\reinforcement\\.venv\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:167: UserWarning: Could not deserialize object clip_range. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: Can't get attribute '_make_function' on <module 'cloudpickle.cloudpickle' from 'c:\\\\Users\\\\mvswa\\\\reinforcement\\\\.venv\\\\lib\\\\site-packages\\\\cloudpickle\\\\cloudpickle.py'>\n",
      "  warnings.warn(\n",
      "c:\\Users\\mvswa\\reinforcement\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:95: UserWarning: You loaded a model that was trained using OpenAI Gym. We strongly recommend transitioning to Gymnasium by saving that model again.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model2=PPO.load('saved_models\\ppo_ryu_2000000_steps_updated.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mvswa\\reinforcement\\.venv\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:167: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: an integer is required (got type bytes)\n",
      "  warnings.warn(\n",
      "c:\\Users\\mvswa\\reinforcement\\.venv\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:167: UserWarning: Could not deserialize object clip_range. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: an integer is required (got type bytes)\n",
      "  warnings.warn(\n",
      "c:\\Users\\mvswa\\reinforcement\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:95: UserWarning: You loaded a model that was trained using OpenAI Gym. We strongly recommend transitioning to Gymnasium by saving that model again.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mvswa\\reinforcement\\.venv\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:751: UserWarning: You are probably loading a model saved with SB3 < 1.7.0, we deactivated exact_match so you can save the model again to avoid issues in the future (see https://github.com/DLR-RM/stable-baselines3/issues/1233 for more info). Original error: Error(s) in loading state_dict for ActorCriticCnnPolicy:\n",
      "\tMissing key(s) in state_dict: \"pi_features_extractor.cnn.0.weight\", \"pi_features_extractor.cnn.0.bias\", \"pi_features_extractor.cnn.2.weight\", \"pi_features_extractor.cnn.2.bias\", \"pi_features_extractor.cnn.4.weight\", \"pi_features_extractor.cnn.4.bias\", \"pi_features_extractor.linear.0.weight\", \"pi_features_extractor.linear.0.bias\", \"vf_features_extractor.cnn.0.weight\", \"vf_features_extractor.cnn.0.bias\", \"vf_features_extractor.cnn.2.weight\", \"vf_features_extractor.cnn.2.bias\", \"vf_features_extractor.cnn.4.weight\", \"vf_features_extractor.cnn.4.bias\", \"vf_features_extractor.linear.0.weight\", \"vf_features_extractor.linear.0.bias\".  \n",
      "Note: the model should still work fine, this only a warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load('saved_models\\\\best_model_5460000.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward for episode 0 is [20540.]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for episode in range(1): \n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model2.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        env.venv.envs[0].render()\n",
    "        time.sleep(0.001)\n",
    "        total_reward += reward\n",
    "    print('Total Reward for episode {} is {}'.format(episode , total_reward))\n",
    "    time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
